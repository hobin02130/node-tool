from flask_sqlalchemy import SQLAlchemy
from werkzeug.security import generate_password_hash, check_password_hash
from datetime import datetime
# ğŸš¨ [ä¿®æ”¹] å¼•å…¥ text ç”¨äºæ‰§è¡ŒåŸç”Ÿ SQLï¼Œå¼•å…¥ IntegrityError ç”¨äºæ•è·ä¸»é”®å†²çª
from sqlalchemy import desc, func, case, BigInteger, literal_column, text
from sqlalchemy.exc import IntegrityError
from flask_login import UserMixin
import json
import os

# =========================================================
#  ç¬¬ä¸€éƒ¨åˆ†ï¼šåŸºç¡€åˆå§‹åŒ–
# =========================================================
db = SQLAlchemy()

# =========================================================
#  ç¬¬äºŒéƒ¨åˆ†ï¼šæ•°æ®åº“æ¨¡å‹å®šä¹‰ (Models)
# =========================================================

class User(UserMixin, db.Model):
    __tablename__ = 'users'
    id = db.Column(db.Integer, primary_key=True)
    username = db.Column(db.String(64)) 
    password_hash = db.Column(db.String(128))

    def set_password(self, password):
        self.password_hash = password

    def check_password(self, password):
        if self.password_hash is None:
            return False
        return self.password_hash == password

class AppSetting(db.Model):
    __tablename__ = 'app_settings'
    key = db.Column(db.String(64), primary_key=True)
    value = db.Column(db.Text)
    description = db.Column(db.String(255))


class Node(db.Model):
    __tablename__ = 'nodes'
    uuid = db.Column(db.String(36), primary_key=True)
    name = db.Column(db.String(128))
    custom_name = db.Column(db.String(128))
    region = db.Column(db.String(16)) 
    expired_at = db.Column(db.DateTime)
    weight = db.Column(db.Integer, default=0)
    traffic_limit = db.Column(db.BigInteger)
    
    # é“¾æ¥å­—æ®µ (JSON) - å…¼å®¹ SQLite/PG ä½¿ç”¨ Text
    links = db.Column(db.Text, default='{}')
    
    # è·¯ç”±ç±»å‹ (0:ç›´è¿, 1:è½åœ°)
    routing_type = db.Column(db.Integer, default=0)
    
    created_at = db.Column(db.DateTime, default=datetime.now)
    updated_at = db.Column(db.DateTime, default=datetime.now, onupdate=datetime.now)
    # cascade='all, delete-orphan' ç¡®ä¿åˆ é™¤ Node æ—¶è‡ªåŠ¨åˆ é™¤å…³è”çš„ HistoryData
    history_data = db.relationship('HistoryData', backref='node', lazy='dynamic', cascade='all, delete-orphan')

    def get_links_dict(self):
        try:
            return json.loads(self.links) if self.links else {}
        except:
            return {}

class HistoryData(db.Model):
    __tablename__ = 'history_data'
    __table_args__ = (db.Index('idx_node_timestamp', 'uuid', 'timestamp'),)
    id = db.Column(db.Integer, primary_key=True)
    uuid = db.Column(db.String(36), db.ForeignKey('nodes.uuid'), nullable=False)
    timestamp = db.Column(db.DateTime, default=datetime.now, index=True)
    total_up = db.Column(db.BigInteger)
    total_down = db.Column(db.BigInteger)
    cpu_usage = db.Column(db.Float)


# =========================================================
#  ç¬¬ä¸‰éƒ¨åˆ†ï¼šå…¨å±€æ“ä½œæ¥å£ (Operations / DAO)
# =========================================================

# --- 1. é…ç½®ç›¸å…³æ“ä½œ ---

def get_config(key, default=None):
    try:
        setting = AppSetting.query.get(key)
        return setting.value if setting else default
    except Exception as e:
        print(f"Error reading config {key}: {e}")
        return default

def set_config(key, value, description=None):
    try:
        setting = AppSetting.query.get(key)
        if not setting:
            setting = AppSetting(key=key)
            db.session.add(setting)
        setting.value = str(value)
        if description:
            setting.description = description
        db.session.commit()
        return True
    except Exception as e:
        db.session.rollback()
        print(f"Error setting config {key}: {e}")
        return False

def get_all_configs():
    try:
        return AppSetting.query.all()
    except Exception as e:
        print(f"Error reading all configs: {e}")
        return []

def get_db_file_size():
    """
    [è¯»] è·å–æ•°æ®åº“å ç”¨å¤§å°ï¼ˆMBï¼‰ã€‚
    è‡ªåŠ¨åˆ¤æ–­æ˜¯ SQLite æ–‡ä»¶å¤§å° è¿˜æ˜¯ PostgreSQL æ•°æ®åº“å ç”¨ã€‚
    """
    try:
        # è·å–é©±åŠ¨åç§°
        driver = db.engine.url.drivername
        
        # æƒ…å†µ A: PostgreSQL
        if 'postgresql' in driver:
            # ä½¿ç”¨ SQL æŸ¥è¯¢è·å–å½“å‰æ•°æ®åº“å¤§å°
            sql = text("SELECT pg_database_size(current_database());")
            result = db.session.execute(sql).scalar()
            if result:
                size_mb = round(result / (1024 * 1024), 2)
                return f"{size_mb} MB"
                
        # æƒ…å†µ B: SQLite
        elif 'sqlite' in driver:
            db_uri = db.engine.url.database
            if db_uri:
                # å¤„ç†ç›¸å¯¹è·¯å¾„
                from flask import current_app
                if not os.path.isabs(db_uri):
                    db_path = os.path.join(current_app.root_path, '..', db_uri)
                else:
                    db_path = db_uri
                
                db_path = os.path.abspath(db_path)
                
                if os.path.exists(db_path):
                    size_bytes = os.path.getsize(db_path)
                    return f"{round(size_bytes / (1024 * 1024), 2)} MB"
        
        return "0.00 MB"
    except Exception as e:
        print(f"Error getting database size: {e}")
        return "è®¡ç®—å¤±è´¥"

# --- 2. èŠ‚ç‚¹ç›¸å…³æ“ä½œ ---

def upsert_node(node_info):
    """[å†™] æ›´æ–°æˆ–æ’å…¥èŠ‚ç‚¹ä¿¡æ¯ (é€šå¸¸ç”± Komari åŒæ­¥ä»»åŠ¡è°ƒç”¨)"""
    try:
        uuid = node_info.get('uuid')
        node = Node.query.get(uuid)
        
        if not node:
            node = Node(uuid=uuid)
            db.session.add(node)
        
        node.name = node_info.get('name')
        if 'custom_name' in node_info:
            node.custom_name = node_info.get('custom_name')
        elif not node.custom_name:
            node.custom_name = node_info.get('name')
            
        node.region = node_info.get('region')
        node.traffic_limit = node_info.get('traffic_limit', 0)
        
        expired_at_str = node_info.get('expired_at')
        if expired_at_str:
            try:
                # å…¼å®¹ ISO æ ¼å¼çš„æ—¶é—´å­—ç¬¦ä¸²
                if expired_at_str.endswith('Z'):
                    expired_at_str = expired_at_str[:-1]
                node.expired_at = datetime.fromisoformat(expired_at_str)
            except ValueError as ve:
                print(f"Warning: Failed to parse datetime string '{expired_at_str}': {ve}")
                node.expired_at = None
        else:
            node.expired_at = None
        
        node.weight = node_info.get('weight')
        
        db.session.commit()
        return True
    except Exception as e:
        db.session.rollback()
        print(f"Error upserting node: {e}")
        return False

def get_total_nodes():
    try:
        return Node.query.count()
    except Exception as e:
        print(f"Error getting total nodes: {e}")
        return 0

def get_all_nodes():
    return Node.query.order_by(Node.weight.desc()).all()

def get_node(uuid):
    return Node.query.get(uuid)

def update_node_custom_name(uuid, custom_name):
    try:
        node = Node.query.get(uuid)
        if node:
            node.custom_name = custom_name
            db.session.commit()
            return True
        return False
    except Exception as e:
        db.session.rollback()
        print(f"Error updating custom name for node {uuid}: {e}")
        return False

def delete_node_by_uuid(uuid):
    try:
        node = Node.query.get(uuid)
        if node:
            db.session.delete(node)
            db.session.commit()
            return True
        return False
    except Exception as e:
        db.session.rollback()
        print(f"Error deleting node {uuid}: {e}")
        return False

def get_nodes_with_latest_traffic():
    try:
        subquery = db.session.query(
            HistoryData.uuid,
            func.max(HistoryData.timestamp).label('max_timestamp')
        ).group_by(HistoryData.uuid).subquery()
        
        query = db.session.query(Node, HistoryData).outerjoin(
            subquery, Node.uuid == subquery.c.uuid
        ).outerjoin(
            HistoryData, 
            db.and_(
                HistoryData.uuid == subquery.c.uuid, 
                HistoryData.timestamp == subquery.c.max_timestamp
            )
        ).order_by(Node.weight.asc())
        
        return query.all()
    except Exception as e:
        print(f"Error fetching nodes with latest traffic: {e}")
        return []

def update_node_details(uuid, links_dict, routing_type, custom_name):
    try:
        node = Node.query.get(uuid)
        if node:
            node.links = json.dumps(links_dict, ensure_ascii=False)
            node.routing_type = int(routing_type)
            node.custom_name = custom_name
            
            db.session.commit()
            return True
        return False
    except Exception as e:
        db.session.rollback()
        print(f"Error updating node details {uuid}: {e}")
        return False

def get_total_consumed_traffic_summary(top_limit=5):
    try:
        total_nodes = Node.query.count()

        max_time_per_node = db.session.query(
            HistoryData.uuid,
            func.max(HistoryData.timestamp).label('max_timestamp')
        ).group_by(HistoryData.uuid).subquery()

        latest_history = db.session.query(
            HistoryData.uuid,
            (HistoryData.total_up + HistoryData.total_down).label('total_usage')
        ).join(
            max_time_per_node,
            db.and_(
                HistoryData.uuid == max_time_per_node.c.uuid,
                HistoryData.timestamp == max_time_per_node.c.max_timestamp
            )
        ).subquery()
        
        total_consumed_traffic = db.session.query(
            func.sum(latest_history.c.total_usage)
        ).scalar() or 0
        
        top_nodes_query = db.session.query(
            Node.custom_name,
            Node.name,
            latest_history.c.total_usage.label('total_usage')
        ).join(
            latest_history, Node.uuid == latest_history.c.uuid
        ).order_by(
            desc(literal_column('total_usage'))
        ).limit(top_limit)

        top_nodes_results = top_nodes_query.all()

        return {
            'total_nodes': total_nodes,
            'total_consumed_traffic': int(total_consumed_traffic),
            'top_traffic_nodes': [
                {
                    'name': result.custom_name or result.name,
                    'traffic': int(result.total_usage)
                } 
                for result in top_nodes_results
            ]
        }
    except Exception as e:
        db.session.rollback()
        print(f"Error fetching dashboard summary data: {e}")
        return {
            'total_nodes': 0,
            'total_consumed_traffic': 0,
            'top_traffic_nodes': []
        }

# --- 3. å†å²æ•°æ®ç›¸å…³æ“ä½œ ---

def get_node_history_by_time_range(uuid, start_time):
    try:
        return HistoryData.query.filter(
            HistoryData.uuid == uuid,
            HistoryData.timestamp >= start_time
        ).order_by(HistoryData.timestamp.asc()).all()
    except Exception as e:
        print(f"Error fetching history for node {uuid}: {e}")
        return []

def get_history_by_date(target_date):
    try:
        if isinstance(target_date, str):
            target_date = datetime.strptime(target_date, '%Y-%m-%d').date()
            
        start_time = datetime.combine(target_date, datetime.min.time())
        end_time = datetime.combine(target_date, datetime.max.time())
        
        records = db.session.query(HistoryData, Node.name, Node.custom_name).join(
            Node, HistoryData.uuid == Node.uuid
        ).filter(
            HistoryData.timestamp >= start_time,
            HistoryData.timestamp <= end_time
        ).order_by(HistoryData.timestamp.asc()).all()
        
        return records
    except Exception as e:
        print(f"Error fetching history by date {target_date}: {e}")
        return []

def add_history_snapshot(uuid, total_up, total_down, cpu):
    try:
        record = HistoryData(
            uuid=uuid,
            total_up=total_up,
            total_down=total_down,
            cpu_usage=cpu,
            timestamp=datetime.now()
        )
        db.session.add(record)
        db.session.commit()
    except Exception as e:
        db.session.rollback()
        print(f"Error adding history: {e}")

# ğŸš¨ [å…³é”®ä¿®å¤] å¢å¼ºç‰ˆæ‰¹é‡å†™å…¥å‡½æ•°
def bulk_add_history(records_list):
    """
    [å†™] æ‰¹é‡å†™å…¥å†å²æ•°æ®ã€‚
    åŠŸèƒ½ï¼š
    1. æ‰‹åŠ¨è¡¥å…… timestampï¼Œè§£å†³ bulk_insert å¿½ç•¥ default é—®é¢˜ã€‚
    2. [PostgreSQL] è‡ªåŠ¨æ•è· Sequence ä¸åŒæ­¥é”™è¯¯å¹¶ä¿®å¤ï¼Œé˜²æ­¢ ID å†²çªã€‚
    """
    try:
        current_time = datetime.now()
        # éå†åˆ—è¡¨ï¼Œç¡®ä¿æ¯æ¡æ•°æ®éƒ½æœ‰ timestamp
        for record in records_list:
            if 'timestamp' not in record:
                record['timestamp'] = current_time
        
        db.session.bulk_insert_mappings(HistoryData, records_list)
        db.session.commit()
    
    except IntegrityError as e:
        # ä¸“é—¨æ•è·å®Œæ•´æ€§é”™è¯¯ (IntegrityError)
        db.session.rollback()
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯ PostgreSQL çš„ "duplicate key" é”™è¯¯
        # e.orig æ˜¯åŸå§‹çš„ DBAPI å¼‚å¸¸å¯¹è±¡
        err_msg = str(e.orig) if hasattr(e, 'orig') else str(e)
        
        if 'duplicate key value' in err_msg and 'history_data_pkey' in err_msg:
            print(">>> [DB Fix] æ£€æµ‹åˆ° ID åºåˆ—ä¸åŒæ­¥ï¼Œæ­£åœ¨è‡ªåŠ¨ä¿®å¤ PostgreSQL åºåˆ—...")
            try:
                # ä»…é’ˆå¯¹ PostgreSQL æ‰§è¡Œä¿®å¤
                # é€»è¾‘ï¼šå°†åºåˆ—å€¼é‡ç½®ä¸º (å½“å‰è¡¨ä¸­æœ€å¤§ID + 1)
                if 'postgresql' in db.engine.url.drivername:
                    sql_fix = text("SELECT setval(pg_get_serial_sequence('history_data', 'id'), (SELECT COALESCE(MAX(id), 0) + 1 FROM history_data), false);")
                    db.session.execute(sql_fix)
                    db.session.commit()
                    
                    print(">>> [DB Fix] åºåˆ—å·²é‡ç½®ï¼Œæ­£åœ¨é‡è¯•å†™å…¥...")
                    # ä¿®å¤åç«‹å³é‡è¯•ä¸€æ¬¡
                    db.session.bulk_insert_mappings(HistoryData, records_list)
                    db.session.commit()
                    print(">>> [DB Fix] é‡è¯•å†™å…¥æˆåŠŸï¼")
                    return
            except Exception as fix_e:
                print(f">>> [DB Fix] è‡ªåŠ¨ä¿®å¤å¤±è´¥: {fix_e}")
                # ä¿®å¤å¤±è´¥åˆ™æŠ›å‡ºåŸå§‹å¼‚å¸¸ï¼Œé¿å…æ©ç›–é—®é¢˜
        
        print(f"Error bulk adding history (IntegrityError): {e}")

    except Exception as e:
        db.session.rollback()
        print(f"Error bulk adding history: {e}")

def get_latest_history(uuid, limit=10):
    return HistoryData.query.filter_by(uuid=uuid)\
        .order_by(desc(HistoryData.timestamp))\
        .limit(limit).all()

# --- 4. ç”¨æˆ·ç›¸å…³æ“ä½œ ---

def get_user_by_username(username):
    try:
        return User.query.filter_by(username=username).first()
    except Exception as e:
        print(f"Error getting user by username: {e}")
        return None

def get_user_by_id(user_id):
    try:
        if user_id is None:
            return None
        return User.query.get(int(user_id))
    except Exception as e:
        print(f"Error getting user by id: {e}")
        return None

def update_user_password(user_id, new_password):
    try:
        user = User.query.get(int(user_id))
        if user:
            user.set_password(new_password)
            db.session.commit()
            return True
        return False
    except Exception as e:
        db.session.rollback()
        print(f"Error updating password: {e}")
        return False