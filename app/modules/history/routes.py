from flask import Blueprint, render_template, jsonify, request, current_app
from flask_login import login_required
from datetime import datetime, timedelta
import traceback

# å¯¼å…¥ db_manager æ¨¡åž‹å’Œæ•°æ®åº“å¯¹è±¡
from app.utils.db_manager import db, HistoryData, get_all_nodes

bp = Blueprint('history', __name__, url_prefix='/history', template_folder='templates')

@bp.route('/')
@login_required
def view_history():
    """åŽ†å²ç»Ÿè®¡é¡µé¢ä¸»é¡µ"""
    nodes = get_all_nodes()
    today = datetime.now().strftime('%Y-%m-%d')
    return render_template('history.html', nodes=nodes, default_date=today)

@bp.route('/api/chart_data')
@login_required
def chart_data_api():
    """
    API: èŽ·å–å›¾è¡¨æ•°æ® (åŒ…å«æ¯å°æ—¶æ¶ˆè€— + ç´¯è®¡è¶‹åŠ¿) + æ‰€æœ‰èŠ‚ç‚¹å½“æ—¥æŽ’åæ•°æ®
    """
    uuid = request.args.get('uuid')
    date_str = request.args.get('date')
    
    if not uuid or not date_str:
        return jsonify({'status': 'error', 'message': 'ç¼ºå°‘å‚æ•°'}), 400

    try:
        # è§£æžæ—¥æœŸèŒƒå›´
        target_date = datetime.strptime(date_str, '%Y-%m-%d').date()
        start_time = datetime.combine(target_date, datetime.min.time())
        end_time = datetime.combine(target_date, datetime.max.time())

        # =================================================
        # 1. æŸ¥è¯¢é€‰ä¸­èŠ‚ç‚¹çš„åŽ†å²è®°å½•
        # =================================================
        # ç¡®ä¿ UUID æ˜¯å­—ç¬¦ä¸²è¿›è¡Œæ¯”è¾ƒ
        uuid = str(uuid)
        
        chart_records = HistoryData.query.filter(
            HistoryData.uuid == uuid,
            HistoryData.timestamp >= start_time,
            HistoryData.timestamp <= end_time
        ).order_by(HistoryData.timestamp.asc()).all()
        
        # ä¸´æ—¶å­˜å‚¨å…¨é‡æ•°æ®çš„åˆ—è¡¨
        raw_times = []
        raw_uploads = []
        raw_downloads = []
        raw_totals = [] 
        
        # åˆå§‹åŒ–24å°æ—¶çš„æ•°æ®æ¡¶
        hourly_stats = {h: {'up': 0.0, 'down': 0.0} for h in range(24)}
        
        if chart_records:
            # A. è®¡ç®—ç´¯è®¡è¶‹åŠ¿ (åŸºäºŽå…¨é‡æ•°æ®è®¡ç®—ï¼Œä¿è¯å‡†ç¡®æ€§)
            base_up = chart_records[0].total_up
            base_down = chart_records[0].total_down
            
            prev_record = chart_records[0]

            for r in chart_records:
                # --- 1. ç´¯è®¡æ•°æ®è®¡ç®— ---
                raw_times.append(r.timestamp.strftime('%H:%M'))
                
                curr_up = r.total_up - base_up
                curr_down = r.total_down - base_down
                
                # å¤„ç†é‡å¯å½’é›¶ (å¦‚æžœå½“å‰æ€»æµé‡å°äºŽåŸºå‡†ï¼Œè¯´æ˜Žé‡å¯è¿‡ï¼Œç›´æŽ¥å–å½“å‰å€¼ä½œä¸ºæ–°åŸºå‡†çš„åç§»)
                # è¿™ç§ç®€å•çš„å¤„ç†æ–¹å¼åœ¨é‡å¯çž¬é—´ä¼šæœ‰è·³å˜ï¼Œä½†èƒ½ä¿è¯åŽç»­å¢žé‡æ­£ç¡®
                if curr_up < 0: curr_up = r.total_up
                if curr_down < 0: curr_down = r.total_down
                
                # è½¬æ¢ä¸º GB
                val_up = curr_up / 1024 / 1024 / 1024
                val_down = curr_down / 1024 / 1024 / 1024
                
                raw_uploads.append(val_up)
                raw_downloads.append(val_down)
                raw_totals.append(val_up + val_down)

                # --- 2. æ¯å°æ—¶å¢žé‡è®¡ç®— ---
                if r != prev_record:
                    delta_up = r.total_up - prev_record.total_up
                    delta_down = r.total_down - prev_record.total_down
                    
                    if delta_up < 0: delta_up = r.total_up
                    if delta_down < 0: delta_down = r.total_down
                    
                    hour = r.timestamp.hour
                    hourly_stats[hour]['up'] += delta_up
                    hourly_stats[hour]['down'] += delta_down
                
                prev_record = r

        # ðŸš¨ [å…³é”®ä¿®å¤] æ•°æ®æŠ½æ · (Downsampling)
        # å¦‚æžœæ•°æ®ç‚¹è¿‡å¤š(ä¾‹å¦‚è¶…è¿‡200ä¸ª)ï¼Œå‰ç«¯æ¸²æŸ“ä¼šéžå¸¸å¡é¡¿ç”šè‡³ä¸æ˜¾ç¤º
        # æˆ‘ä»¬åœ¨è¿™é‡Œè¿›è¡Œå‡åŒ€æŠ½æ ·ï¼Œåªè¿”å›žçº¦ 150 ä¸ªç‚¹ç»™å‰ç«¯
        MAX_POINTS = 150
        total_points = len(raw_times)
        
        if total_points > MAX_POINTS:
            step = total_points // MAX_POINTS
            # ä½¿ç”¨åˆ‡ç‰‡è¿›è¡ŒæŠ½æ ·
            final_times = raw_times[::step]
            final_uploads = [round(x, 4) for x in raw_uploads[::step]]
            final_downloads = [round(x, 4) for x in raw_downloads[::step]]
            final_totals = [round(x, 4) for x in raw_totals[::step]]
            
            # ç¡®ä¿æœ€åŽä¸€ä¸ªç‚¹æ€»æ˜¯åŒ…å«åœ¨å†…ï¼Œæ˜¾ç¤ºæœ€æ–°çŠ¶æ€
            if total_points > 0 and (total_points - 1) % step != 0:
                final_times.append(raw_times[-1])
                final_uploads.append(round(raw_uploads[-1], 4))
                final_downloads.append(round(raw_downloads[-1], 4))
                final_totals.append(round(raw_totals[-1], 4))
        else:
            # æ•°æ®é‡ä¸å¤§ï¼Œç›´æŽ¥ä¿ç•™å¹¶å–æ•´
            final_times = raw_times
            final_uploads = [round(x, 4) for x in raw_uploads]
            final_downloads = [round(x, 4) for x in raw_downloads]
            final_totals = [round(x, 4) for x in raw_totals]

        # æ ¼å¼åŒ–æ¯å°æ—¶æ•°æ®
        bar_hours = [f"{h:02d}:00" for h in range(24)]
        bar_up = [round(hourly_stats[h]['up'] / 1024 / 1024 / 1024, 4) for h in range(24)]
        bar_down = [round(hourly_stats[h]['down'] / 1024 / 1024 / 1024, 4) for h in range(24)]

        # =================================================
        # 2. ç”Ÿæˆæ‰€æœ‰èŠ‚ç‚¹çš„å½“æ—¥ç”¨é‡æŽ’å
        # =================================================
        all_nodes = get_all_nodes()
        ranking_data = []
        
        # é¢„å…ˆèŽ·å–å½“å‰é€‰æ‹©çš„èŠ‚ç‚¹ ID (ç¡®ä¿æ˜¯å­—ç¬¦ä¸²)
        current_uuid_str = str(uuid)

        for node in all_nodes:
            node_uuid_str = str(node.uuid)
            try:
                # ä¼˜åŒ–æŸ¥è¯¢ï¼šåªæŸ¥å¤´å°¾ï¼Œé¿å…å…¨è¡¨æ‰«æ
                # æ³¨æ„ï¼šåœ¨ PG ä¸­è¿™é‡Œçš„æŸ¥è¯¢å¦‚æžœæ•°æ®é‡å·¨å¤§å¯èƒ½ä¼šæ…¢ï¼Œä½†é€šå¸¸æœ‰ç´¢å¼• idx_node_timestamp ä¼šå¾ˆå¿«
                first = HistoryData.query.filter(
                    HistoryData.uuid == node_uuid_str, 
                    HistoryData.timestamp >= start_time
                ).order_by(HistoryData.timestamp.asc()).first()
                
                last = HistoryData.query.filter(
                    HistoryData.uuid == node_uuid_str, 
                    HistoryData.timestamp <= end_time
                ).order_by(HistoryData.timestamp.desc()).first()
                
                usage_total = 0
                usage_up = 0
                usage_down = 0
                
                if first and last:
                    d_up = last.total_up - first.total_up
                    d_down = last.total_down - first.total_down
                    
                    if d_up < 0: d_up = last.total_up
                    if d_down < 0: d_down = last.total_down
                    
                    usage_up = round(d_up / 1024 / 1024 / 1024, 3)
                    usage_down = round(d_down / 1024 / 1024 / 1024, 3)
                    usage_total = round(usage_up + usage_down, 3)
                
                ranking_data.append({
                    'name': node.custom_name or node.name,
                    'uuid': node_uuid_str, 
                    'region': node.region,
                    'usage': usage_total,
                    'up': usage_up,
                    'down': usage_down,
                    'is_current': (node_uuid_str == current_uuid_str)
                })
            except Exception as e:
                # æ•èŽ·å•ä¸ªèŠ‚ç‚¹æŸ¥è¯¢é”™è¯¯ï¼Œé˜²æ­¢æ•´ä¸ªæŽ¥å£å´©æºƒ
                print(f"Error processing node {node.name}: {e}")
                continue
            
        # é™åºæŽ’åˆ—
        ranking_data.sort(key=lambda x: x['usage'], reverse=True)

        return jsonify({
            'status': 'success',
            'data': {
                'line': {
                    'times': final_times,
                    'uploads': final_uploads,
                    'downloads': final_downloads,
                    'totals': final_totals
                },
                'bar': {
                    'hours': bar_hours,
                    'up': bar_up,
                    'down': bar_down
                },
                'ranking': ranking_data
            }
        })

    except Exception as e:
        print(f"API Error: {e}")
        traceback.print_exc() # æ‰“å°å®Œæ•´å †æ ˆä¿¡æ¯åˆ°æŽ§åˆ¶å°ï¼Œæ–¹ä¾¿è°ƒè¯•
        return jsonify({'status': 'error', 'message': str(e)}), 500